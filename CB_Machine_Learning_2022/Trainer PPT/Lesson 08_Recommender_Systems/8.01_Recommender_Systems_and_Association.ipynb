{"cells":[{"cell_type":"markdown","metadata":{"id":"zeD8WGmObs_I"},"source":["# <b> Recommender Systems </b>"]},{"cell_type":"markdown","metadata":{"id":"9pRCzhgK6--S"},"source":["## <b>Learning Objectives</b>\n","\n","In this lesson, we will cover the following concepts:\n","\n","- Recommendation system\n","- The long tail\n","- A simple popularity-based recommender system\n","- A collaborative filtering model\n","- Evaluating a recommendation system"]},{"cell_type":"markdown","metadata":{"id":"AyBTaf1Um-qn"},"source":["### **What Is a Recommender System?**\n"," \n","A recommender or recommendation system is a subclass of an information filtering system that seeks to predict the rating or preference that a user would give to an item.\n","\n","Let’s consider the example shown in the figure below. Here, we have a user database, that is, data consisting of items rated by the user. Now, let’s suppose that a new user visits and likes five out of ten items on the website. A recommender system recommends the items that the new user might like, based on similarity with other items. We will dive deeper  into this concept in the coming sections. \n"]},{"cell_type":"markdown","metadata":{"id":"5aGzv3xen2xm"},"source":["![recommender_system_info](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/Applied_Machine_Learning/Images/Lesson_08_Recomendar_Systems/recommender_system_info.jpg)"]},{"cell_type":"markdown","metadata":{"id":"DXX4hO4On8Lx"},"source":["## **The Theory of Long Tail**\n","\n","- It shows how products in low demand or with low sales volume can collectively make up a market share that exceeds the relatively few current bestsellers and blockbusters but only if the store or distribution channel is large enough.\n","\n","- The long tail concept looks at less popular goods in lower demand. The use of these goods could increase profitability as consumers  navigate  away from mainstream markets.\n","\n","- This can be easily understood by looking at the figure [below](https://www.wired.com/2004/10/tail/)."]},{"cell_type":"markdown","metadata":{"id":"nuQ8BaiPoIHR"},"source":["![longtail](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/Applied_Machine_Learning/Images/Lesson_08_Recomendar_Systems/longtail.png)"]},{"cell_type":"markdown","metadata":{"id":"o1qQWaoOojLA"},"source":["The figure above clearly shows the use of long tail by [Rhapsody](https://en.wikipedia.org/wiki/Rhapsody_(music) where they sell music albums both online and off-line. We can clearly observe the following:\n"," \n","- Both Rhapsody and Walmart sell the most popular music albums online, but the former offers 19 times more songs than Walmart. Even though there is a demand for popular music albums, there is also a demand for the less popular online. Recommender systems leverage these less popular items online. \n"]},{"cell_type":"markdown","metadata":{"id":"3aSHoiRroo4Z"},"source":["## Recommend the Most Popular Items\n"," \n","- Let's consider the movie dataset. We will look carefully at the user ratings and think about what can be done.\n","\n","- The answer that strikes first is the **most popular item**. This is exactly what we will be doing.\n","\n","- Technically, this is the fastest method, but it does come with a major drawback, which is a lack of personalization. The dataset has many files; we will be looking at a few of them, mainly the ones that relate to movie ratings."]},{"cell_type":"markdown","metadata":{"id":"j9LYKSEPowS2"},"source":["## **Popularity-Based Recommender System**\n","\n","- There is a division by section, so the user can look at the section of his or her interest.\n","\n","- At a time, there are only a few hot topics; there is a high chance that a user wants to read the news which is being read by most others."]},{"cell_type":"markdown","metadata":{"id":"2mtzsCgznHms"},"source":["\n","\n","### Import Libraries"]},{"cell_type":"markdown","metadata":{"id":"KDSJS_0nnHm6"},"source":["In python, Pandas is used for data manipulation and analysis. NumPy is a package that includes a multidimensional array object and multiple derived objects. Matplotlib is an amazing visualization library in Python for 2D plots of arrays. Seaborn is an open-source Python library built on top of matplotlib. Mean_squared_error is a library that measures the average of the squares of the errors, which is the average squared difference between the estimated values and the actual value.\n","\n","These libraries are written with the import keyword.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kVkjskscnziR"},"outputs":[],"source":["import pandas as pd\n","import os, io\n","import numpy as np\n","from pandas import Series, DataFrame, read_table\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import warnings\n","warnings.filterwarnings('ignore')\n","from sklearn.metrics import mean_squared_error\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"0vK9Csh_nHnA"},"source":["\n","### Exporting Dataset from Zip File\n"]},{"cell_type":"markdown","metadata":{"id":"p39KrFtTnHnC"},"source":["Before reading data you need to download \"ml-100k.zip\" dataset from the resource section and upload it into the Lab. We will use Up arrow icon which is shown in the left side under View icon. Click on the Up arrow icon and upload the file wherever it is downloaded into your system.\n","\n","After this you will see the downloaded file will be visible on the left side of your lab with all the .ipynb files.\n","\n","Then, the below snippet will extract the zip dataset to the corresponding folder.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GL-BUaFtnHnE"},"outputs":[],"source":["import zipfile\n","with zipfile.ZipFile('ml-100k.zip', 'r') as zip_ref:\n","    zip_ref.extractall(\".\")"]},{"cell_type":"markdown","metadata":{"id":"jQDvCWSQpIYQ"},"source":["We start to explore the data set of movie ratings and our interest lies particularly  in ratings. Let's see how we recommend the most popular (that is, highly rated) movies."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0k4WTfl3o_DS"},"outputs":[],"source":["#Load the Ratings data\n","r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n","ratings = read_table('ml-100k//u.data',header=None,sep='\\t')\n","ratings.columns = r_cols\n","\n","i_cols = ['movie_id', 'movie title' ,'release date','video release date', 'IMDb URL', 'unknown', 'Action', 'Adventure',\n"," 'Animation', 'Children\\'s', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n"," 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n","items = read_table('./ml-100k//u.item', sep='|',names=i_cols,\n"," encoding='latin-1')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wbg9tfb6pPF7"},"outputs":[],"source":["ratings.head()"]},{"cell_type":"markdown","metadata":{"id":"5LjMznLynHnH"},"source":["\n","Ratings is a variable that stores all the columns from the ml-100k dataset in the u.data file.\n"," The head() function displays the first five rows from ratings.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"R_crW98LpRdU"},"source":["## Let's Build a Popularity-Based Recommender System"]},{"cell_type":"markdown","metadata":{"id":"jtGNMS7EpXNS"},"source":["With our initial exploration, we decided that ideal data would be the one where we could also have the movie ratings with us. Let's see how we are able to do this.\n","\n","\n","\n","We will use the pd.merge function that is used to combine data on common columns or indices.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YQr8lbNOpec8"},"outputs":[],"source":["new_data = pd.merge(items,ratings,on='movie_id')\n","new_data  = new_data[['movie_id','movie title','user_id','rating']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QdkWukqjpgwp"},"outputs":[],"source":["new_data.head()"]},{"cell_type":"markdown","metadata":{"id":"kSlHfcEwnHnL"},"source":["\n","New_data is a variable that stores data read by the pd.merge function. It consists of items and ratings.\n"," The head() function displays the first five rows from new_data.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"j-K7VCBhplti"},"source":["Before proceeding to build the recommender system, we will observe the following steps to recommend movies:\n","- Find unique users\n","- Count the number of times the movie has been seen\n","- [Rank](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.rank.html) the scores (counts)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oxNidflkpoZq"},"outputs":[],"source":["def popularity(train,title,ids):\n","    train_data_grouped = train.groupby([title])[ids].count().reset_index()  #user_id  #movie title\n","    train_data_grouped.rename(columns = {ids: 'score'},inplace=True)            \n","    train_data_sort = train_data_grouped.sort_values(['score',title], ascending = [0,1])\n","    train_data_sort['Rank'] = train_data_sort['score'].rank(ascending=0, method='first')\n","    popularity_recommendations = train_data_sort.head(10) \n","    return popularity_recommendations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kq1aSt_Xpq4Q"},"outputs":[],"source":["popularity(new_data,'movie title','user_id')"]},{"cell_type":"markdown","metadata":{"id":"F3n8BKX5pwsh"},"source":["## Drawback\n","\n","Having recommended the movies, we can immediately conclude that the major drawback of such a system would be the **lack of personalization**."]},{"cell_type":"markdown","metadata":{"id":"SiLpRPIap8FM"},"source":["## **Collaborative Filtering**\n"," \n","In the newer, narrower sense, collaborative filtering is a method of making automatic predictions (filtering) about the interests of a user by collecting preferences or taste information from many users (collaborating). The underlying assumption of the collaborative filtering approach is that if person A has the same opinion as person B on an issue, A is more likely to have B's opinion on a different issue than that of a randomly chosen person."]},{"cell_type":"markdown","metadata":{"id":"Q-qJKeHlqFkc"},"source":["## Types of Collaborative Filtering\n"," \n","### User-Based Collaborative Filtering\n"," \n","In this type, we find look-alike customers (based on similarity) and offer products that the first customer's look-alike chose in the past. This algorithm is very effective but takes a lot of time and resources. It computes every customer pair information, which takes time. Therefore, for big base platforms, this algorithm is hard to implement without a very strong parallelizing system.\n"," \n","1. Build a matrix of things each user bought or viewed or rated\n","2. Compute similarity scores between users\n","3. Find users similar to you\n","4. Recommend stuff they bought or viewed or rated that you haven’t yet\n"," \n","### Problems \n","1. People are fickle, so their tastes tend to change\n","2. There are usually more people than things"]},{"cell_type":"markdown","metadata":{"id":"YebwClzFqKlU"},"source":["### Item-Based Collaborative Filtering\n"," \n","It is quite similar to the previous algorithm, but instead of finding customer look-alikes, it tries to find items that look alike. Once we have an item look-alike matrix, we can easily recommend similar items to customers who have purchased an item from the store. This algorithm is far less resource-consuming than user-based collaborative filtering. \n"," \n","1. Find every pair of movies that were watched by the same person\n","2. Measure the similarity of rating across all the users who watched both\n","3. Sort movies by the similarity strength\n"," \n","\n","### Interesting fact \n"," \n","Item-based collaboration is extensively used in Amazon, and they came out with it in great detail. You can read more at [Amazon](https://www.cs.umd.edu/~samir/498/Amazon-Recommendations.pdf)\n","\n","\n","Let's get started with building our item-based collaborative recommender system. For convenience, let's split this into two parts. \n","\n","- To find similarities between items\n","- To recommend them to users"]},{"cell_type":"markdown","metadata":{"id":"8Q4u9lLEqVY4"},"source":["Item-based collaborative filtering would be the most feasible solution, as the number of items is always lesser than the number of users and it improves the computational speed."]},{"cell_type":"markdown","metadata":{"id":"chitFAWmqam-"},"source":["**Leverage the Pandas** \n"," \n","- To begin with, we will use the pandas pivot table to look at relationships between movies and we will use the pivot table in pandas. Pivot table in pandas is an excellent tool to summarize one or more numeric variable based on two other categorical variables.\n","\n","- We start building a utility matrix (matrix consisting of movies and ratings)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tSkaUlUtqa-Y"},"outputs":[],"source":["movie_ratings = new_data.pivot_table(index=['user_id'],columns=['movie title'],values='rating')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PlDJIAuuqgxR"},"outputs":[],"source":["movie_ratings.head()"]},{"cell_type":"markdown","metadata":{"id":"eoiYDt-KqlcT"},"source":["The above table gives information about the rating given by each user against the movie title. There are many NaN as it is not necessary for each user to review each movie. Let’s start by looking at the geeks' most favorite, Star Wars, and see how it correlates pairwise with other movies in the table."]},{"cell_type":"markdown","metadata":{"id":"sKjgXQSHqqsY"},"source":["## Similarity Function\n","\n","To decide the similarity between two items in the dataset, let's briefly look at the popular similarity functions.\n","\n","### Terminology\n","\n","- Let $\\textbf{$r_x$}$ denote the rating of the item x given by the user and $\\textbf{$r_y$}$ be the rating of item y. To find the similarity pairwise between two items the following metrics can be used:\n","\n","## cosine Index\n","\n","$$sim(\\textbf{$r_{x}$},\\textbf{$r_y$}) = cos(\\textbf{$r_x$},\\textbf{$r_y$}) = \\dfrac{\\textbf{$r_x$}\\textbf{$r_y$}}{||\\textbf{$r_x$}||\\  ||\\textbf{$r_y$}||} $$ \n","\n","The major problem is that it treats missing values as negative.\n","\n","## Pearson Index\n","\n","$S_{xy}$ = Items x and y both have ratings\n","\n","$$sim(\\textbf{$r_{x}$},\\textbf{$r_y$})=\\dfrac{\\sum_{x\\epsilon s}(\\textbf{$r_{xs}$}- \\textbf{$r_{xm}$})(\\textbf{$r_{ys}$}- \\textbf{$r_y$})}{(\\sqrt{\\sum_{s\\epsilon s_{xy}}(\\textbf{$r_{xs}$}- \\textbf{$r_{xm}$})^2}(\\sqrt{\\sum_{s\\epsilon s_{xy}}(\\textbf{$r_{ys}$}- \\textbf{$r_{ym}$})^2}} $$ \n","\n","## Jaccard Index\n","\n","$$Jaccard \\ Index = \\dfrac{Number \\ in\\  both \\  sets}{Number \\  in\\  either \\ set}  $$"]},{"cell_type":"markdown","metadata":{"id":"B-KYZWk5MD_e"},"source":["Let's start with the Pearson Index in this case. Now that we have understood how similar products can be found, let's start with the movie, Star Wars."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Al4Cuqvql3D"},"outputs":[],"source":["StarWarsRatings = movie_ratings['Star Wars (1977)'] \n","StarWarsRatings.head()"]},{"cell_type":"markdown","metadata":{"id":"fWHvhtoaMjpj"},"source":["Now, let’s use the **corrwith()** function to check the pairwise correlation of Star Wars’s user rating with other films in the column."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mZUujNjnMkC-"},"outputs":[],"source":["similarmovies = movie_ratings.corrwith(StarWarsRatings)\n","similarmovies =similarmovies.dropna()\n","df = pd.DataFrame(similarmovies)\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"GLGPBJ3-Q7ev"},"source":["If we look at the data closely, we will find something incorrect. \n","\n","The potential reason here is that a handful of people who have seen obscure films are messing up our movies. We want to get rid of the movies that only a few people have watched that show incorrect results.\n","\n","We have used groupby function that involves some combination of splitting the object, applying a function, and combining the results and sort_values function that sorts by the values along either axis."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z6jUUrHEQ9D6"},"outputs":[],"source":["movie_stats = new_data.groupby('movie title').agg({'rating':[np.size,np.mean]})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k73G50biRGTi"},"outputs":[],"source":["check = movie_stats.sort_values([('rating','mean')],ascending=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HGS5NyiyRIEd"},"outputs":[],"source":["check.head()"]},{"cell_type":"markdown","metadata":{"id":"jbb-9LHaRR9v"},"source":["Now, we can clearly observe that there are movies that have very few rating counts (size). Therefore, we set a threshold of the movie count to have at least 100 ratings."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6g9e6Is3RSnn"},"outputs":[],"source":["popularmovies = movie_stats['rating']['size']>=100\n","\n","movie_stats[popularmovies].sort_values([('rating','mean')],ascending=False)[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HKx15-dwRWIQ"},"outputs":[],"source":["df = movie_stats[popularmovies].join(DataFrame(similarmovies,columns=['similarity']))\n","df.sort_values('similarity',ascending=False)[:20]"]},{"cell_type":"markdown","metadata":{"id":"VUTxyIY7Teu8"},"source":["## Building an End-to-End Recommender System\n","\n","We will list points that need to be followed to recommend a movie based on what we did till now :\n","\n","- Compute the correlation score for every pair in the matrix\n","- Choose a user and find his or her movies of interest\n","- Recommend movies to him or her\n","- Improve on the recommendation\n","\n","The pandas method **corr()** will compute the correlation score for every pair in the matrix. This gives a correlation score between every pair of movies in turn creating a sparse matrix. Let's see how this looks."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VznjRdJzThvo"},"outputs":[],"source":["corrMatrix = movie_ratings.corr(method='pearson',min_periods=100)\n","corrMatrix.head()"]},{"cell_type":"markdown","metadata":{"id":"L7t54Cc0Tmdj"},"source":["Now, we want to recommend movies to a friend, so let's have a look at the movies our friend has rated."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XGZQFplHToPN"},"outputs":[],"source":["friend_ratings = movie_ratings.loc[1].dropna()[1:4]\n","friend_ratings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Buzl1n8OTq9C"},"outputs":[],"source":["simcandidates= pd.Series()\n","for i in range(0,len(friend_ratings.index)):\n","    print('Adding similars to ', friend_ratings.index[i])\n","    \n","    print('--------------------------------')\n","    sims = corrMatrix[friend_ratings.index[i]].dropna()\n","    sims = sims.map(lambda x: x*friend_ratings[i]) # Assigning lower weights to movies with lower ratings.\n","    simcandidates  = simcandidates.append(sims)\n","    \n","    print('sorting')\n","    \n","    simcandidates.sort_values(inplace=True,ascending=False)\n","    \n","    print(simcandidates.head(10))"]},{"cell_type":"markdown","metadata":{"id":"4y_Gh7yuTttS"},"source":["Some movies come up more than once, because they are very similar to the ones that the user has rated. Let's eliminate them."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UnUvVrh6Tv4_"},"outputs":[],"source":["simcandidates = simcandidates.groupby(simcandidates.index).sum()\n","simcandidates.sort_values(inplace=True,ascending=False)\n","simcandidates.head(10)"]},{"cell_type":"markdown","metadata":{"id":"W6lWp08fT7CD"},"source":["Having done all the computations using pandas, we can see that it is computationally intensive. We have a Python module that does that for us."]},{"cell_type":"markdown","metadata":{"id":"nojJgrATVy8Y"},"source":["## Using the Surprise Module\n","\n","[Python Surprise](http://surprise.readthedocs.io/en/stable/index.html) is an easy-to-use Python scikit for recommender systems. Let's see how to build a recommender system using the surprise module and focus on the model inspired by K-Nearest Neighbors (KNN)."]},{"cell_type":"markdown","metadata":{"id":"ni4pIlMMZl1j"},"source":["## Common Practice\n","\n","1. Define Similarity $S_{ij}$ in terms of i and j\n","2. Select K nearest neighbors N(i;X)\n","    - Items most similar to i that were rated by X\n","3. Estimate rating $r_{xi}$ as the weighted average\n","\n","$$ r_{x_i} = b_{x_i} + \\dfrac{\\sum_{j \\epsilon N(i;x)} S_{ij} (r_{x_j} - b_{x_j})}{\\sum_{j \\epsilon N(i;x)} S_{ij}} $$\n","\n","Here, the term $b_{x_i}$ is the baseline estimator for the rating comprising three terms: the overall mean movie rating, rating deviation of user x, and rating deviation of the movie i."]},{"cell_type":"markdown","metadata":{"id":"7zV0FdBfZuIN"},"source":["## **Evaluation Metrics**\n","#### Comparing Predictions with Known Ratings\n","\n","**RMSE**\n","\n","- Root Mean Square Error (RMSE) \n","    - $ \\sqrt{\\frac{1}{N}\\sum_{x_i}(\\textbf{$r_{x_i}$- $r_{x_i}^*$})^2}$ here $r_{x_i}$ is the predicted rating and $r_{x_i}^*$ is the actual rating\n","- Precision at top 10 \n","    - % of those in top 10"]},{"cell_type":"markdown","metadata":{"id":"ath4Uk1sWjya"},"source":["**Note: In this lesson, we saw the use of the recommender systems.**"]},{"cell_type":"markdown","metadata":{"id":"s-xenulhnptC"},"source":["![Simplilearn_Logo](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/Logo_Powered_By_Simplilearn/SL_Logo_1.png)"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"8.01_Recommender_Systems_and_Association.ipynb","private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":0}