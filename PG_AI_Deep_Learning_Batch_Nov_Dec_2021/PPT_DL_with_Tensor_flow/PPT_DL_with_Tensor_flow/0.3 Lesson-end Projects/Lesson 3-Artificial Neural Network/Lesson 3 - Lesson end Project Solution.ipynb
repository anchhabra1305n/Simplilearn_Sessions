{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -9,   5,   6,  -9,   7,  -8,  -6,   3,  -3],\n",
       "       [  0,   9, -10,   5,   0,  -7,  -1,  -2,   6],\n",
       "       [  6,   1,  -7,  -8,  -9,   6,   2,  -7,  -3],\n",
       "       [ -5, -10,   3,  -9,  -1,  -9,  -8,   1,  -3]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "input_nodes = 9\n",
    "hidden_nodes = 4\n",
    "output_nodes = 6\n",
    "wei_inp_hid = np.random.randint(-10, 10, (hidden_nodes, input_nodes))\n",
    "wei_inp_hid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3, 4, 7, 8]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_input_percentage = 0.6\n",
    "active_input_nodes = int(input_nodes * active_input_percentage)\n",
    "active_input_indices = sorted(random.sample(range(0, input_nodes), \n",
    "                              active_input_nodes))\n",
    "active_input_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9, -9,  7,  3, -3],\n",
       "       [ 0,  5,  0, -2,  6],\n",
       "       [ 6, -8, -9, -7, -3],\n",
       "       [-5, -9, -1,  1, -3]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei_inp_hid_old = wei_inp_hid.copy()\n",
    "wei_inp_hid = wei_inp_hid[:, active_input_indices]\n",
    "wei_inp_hid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  7  -1  -1   5]\n",
      " [  1   4   7   1]\n",
      " [ -1  -4  -4 -10]\n",
      " [  8   3  -7   6]\n",
      " [  4  -1   3   3]\n",
      " [  1  -7   1  -9]]\n",
      "[0, 1]\n",
      "[[ 7 -1]\n",
      " [ 1  4]\n",
      " [-1 -4]\n",
      " [ 8  3]\n",
      " [ 4 -1]\n",
      " [ 1 -7]]\n"
     ]
    }
   ],
   "source": [
    "wei_hid_out = np.random.randint(-10, 10, (output_nodes, hidden_nodes))\n",
    "print(wei_hid_out)\n",
    "active_hidden_percentage = 0.7\n",
    "active_hidden_nodes = int(hidden_nodes * active_hidden_percentage)\n",
    "active_hidden_indices = sorted(random.sample(range(0, hidden_nodes), \n",
    "                             active_hidden_nodes))\n",
    "print(active_hidden_indices)\n",
    "wei_hid_out_old = wei_hid_out.copy()\n",
    "wei_hid_out = wei_hid_out[:, active_hidden_indices]\n",
    "print(wei_hid_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9, -9,  7,  3, -3],\n",
       "       [ 0,  5,  0, -2,  6]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei_inp_hid = wei_inp_hid[active_hidden_indices]\n",
    "wei_inp_hid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wei_inp_hid: \n",
      " [[ 2  3 -6  7  0 -5  7 -4  0 -6]\n",
      " [ 3  2 -2 -5 -1 -2 -3  8  3 -1]\n",
      " [ 8 -7  2  8 -2  8  7 -8  1 -8]\n",
      " [-8 -9 -6 -3  5 -9 -4  2 -5  9]\n",
      " [-2  4  4 -6  1 -2 -2  8 -7 -3]]\n",
      "wei_hid_out:\n",
      " [[-10   6  -7  -4  -5]\n",
      " [  1   1   4   5   0]\n",
      " [  4  -8  -9   0   1]\n",
      " [  8  -1   0  -4  -1]\n",
      " [  5   8  -6   4  -5]\n",
      " [  0  -6 -10   9   6]\n",
      " [  0  -7   2  -3   1]]\n",
      "\n",
      "active input indices:  [2, 3, 5, 6, 7, 8, 9]\n",
      "active hidden indices:  [1, 2, 4]\n",
      "\n",
      "weight_input_hidden after deactivating input nodes:\n",
      " [[-6  7 -5  7 -4  0 -6]\n",
      " [-2 -5 -2 -3  8  3 -1]\n",
      " [ 2  8  8  7 -8  1 -8]\n",
      " [-6 -3 -9 -4  2 -5  9]\n",
      " [ 4 -6 -2 -2  8 -7 -3]]\n",
      "\n",
      "weight_input_hidden after deactivating hidden nodes:\n",
      " [[-2 -5 -2 -3  8  3 -1]\n",
      " [ 2  8  8  7 -8  1 -8]\n",
      " [ 4 -6 -2 -2  8 -7 -3]]\n",
      "\n",
      "weight_output_hidden after deactivating hidden nodes:\n",
      " [[  6  -7  -5]\n",
      " [  1   4   0]\n",
      " [ -8  -9   1]\n",
      " [ -1   0  -1]\n",
      " [  8  -6  -5]\n",
      " [ -6 -10   6]\n",
      " [ -7   2   1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "input_nodes = 10\n",
    "hidden_nodes = 5\n",
    "output_nodes = 7\n",
    "wei_inp_hid = np.random.randint(-10, 10, (hidden_nodes, input_nodes))\n",
    "print(\"wei_inp_hid: \\n\", wei_inp_hid)\n",
    "wei_hid_out = np.random.randint(-10, 10, (output_nodes, hidden_nodes))\n",
    "print(\"wei_hid_out:\\n\", wei_hid_out)\n",
    "active_input_percentage = 0.7\n",
    "active_hidden_percentage = 0.7\n",
    "active_input_nodes = int(input_nodes * active_input_percentage)\n",
    "active_input_indices = sorted(random.sample(range(0, input_nodes), \n",
    "                              active_input_nodes))\n",
    "print(\"\\nactive input indices: \", active_input_indices)\n",
    "active_hidden_nodes = int(hidden_nodes * active_hidden_percentage)\n",
    "active_hidden_indices = sorted(random.sample(range(0, hidden_nodes), \n",
    "                             active_hidden_nodes))\n",
    "print(\"active hidden indices: \", active_hidden_indices)\n",
    "wei_inp_hid_old = wei_inp_hid.copy()\n",
    "wei_inp_hid = wei_inp_hid[:, active_input_indices]\n",
    "print(\"\\nweight_input_hidden after deactivating input nodes:\\n\", wei_inp_hid)\n",
    "wei_inp_hid = wei_inp_hid[active_hidden_indices]\n",
    "print(\"\\nweight_input_hidden after deactivating hidden nodes:\\n\", wei_inp_hid)\n",
    "wei_hid_out_old = wei_hid_out.copy()\n",
    "wei_hid_out = wei_hid_out[:, active_hidden_indices]\n",
    "print(\"\\nweight_output_hidden after deactivating hidden nodes:\\n\", wei_hid_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from scipy.special import expit as activation_function\n",
    "from scipy.stats import truncnorm\n",
    "def truncated_normal(mean=0, sd=1, low=0, upp=10):\n",
    "    return truncnorm(\n",
    "        (low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd)\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 no_of_in_nodes, \n",
    "                 no_of_out_nodes, \n",
    "                 no_of_hidden_nodes,\n",
    "                 learning_rate,\n",
    "                 bias=None\n",
    "                ):  \n",
    "        self.no_of_in_nodes = no_of_in_nodes\n",
    "        self.no_of_out_nodes = no_of_out_nodes       \n",
    "        self.no_of_hidden_nodes = no_of_hidden_nodes          \n",
    "        self.learning_rate = learning_rate \n",
    "        self.bias = bias\n",
    "        self.create_weight_matrices()\n",
    "        \n",
    "    def create_weight_matrices(self):\n",
    "        X = truncated_normal(mean=2, sd=1, low=-0.5, upp=0.5)\n",
    "        \n",
    "        bias_node = 1 if self.bias else 0\n",
    "        n = (self.no_of_in_nodes + bias_node) * self.no_of_hidden_nodes\n",
    "        X = truncated_normal(mean=2, sd=1, low=-0.5, upp=0.5)\n",
    "        self.wei_inp_hid = X.rvs(n).reshape((self.no_of_hidden_nodes, \n",
    "                                                   self.no_of_in_nodes + bias_node))\n",
    "        n = (self.no_of_hidden_nodes + bias_node) * self.no_of_out_nodes\n",
    "        X = truncated_normal(mean=2, sd=1, low=-0.5, upp=0.5)\n",
    "        self.wei_hid_out = X.rvs(n).reshape((self.no_of_out_nodes, \n",
    "                                                    (self.no_of_hidden_nodes + bias_node)))\n",
    "    def dropout_weight_matrices(self,\n",
    "                                active_input_percentage=0.70,\n",
    "                                active_hidden_percentage=0.70):\n",
    "        # restore wei_inp_hid array, if it had been used for dropout\n",
    "        self.wei_inp_hid_orig = self.wei_inp_hid.copy()\n",
    "        self.no_of_in_nodes_orig = self.no_of_in_nodes\n",
    "        self.no_of_hidden_nodes_orig = self.no_of_hidden_nodes\n",
    "        self.wei_hid_out_orig = self.wei_hid_out.copy()\n",
    "        \n",
    "        active_input_nodes = int(self.no_of_in_nodes * active_input_percentage)\n",
    "        active_input_indices = sorted(random.sample(range(0, self.no_of_in_nodes), \n",
    "                                      active_input_nodes))\n",
    "        active_hidden_nodes = int(self.no_of_hidden_nodes * active_hidden_percentage)\n",
    "        active_hidden_indices = sorted(random.sample(range(0, self.no_of_hidden_nodes), \n",
    "                                       active_hidden_nodes))\n",
    "        \n",
    "        self.wei_inp_hid = self.wei_inp_hid[:, active_input_indices][active_hidden_indices]       \n",
    "        self.wei_hid_out = self.wei_hid_out[:, active_hidden_indices]\n",
    "        \n",
    "        self.no_of_hidden_nodes = active_hidden_nodes\n",
    "        self.no_of_in_nodes = active_input_nodes\n",
    "        return active_input_indices, active_hidden_indices\n",
    "    \n",
    "    def weight_matrices_reset(self, \n",
    "                              active_input_indices, \n",
    "                              active_hidden_indices):\n",
    "        \n",
    "        \"\"\"\n",
    "        self.wei_inp_hid and self.wei_hid_out contain the newly adapted values from the active nodes.\n",
    "        We have to reconstruct the original weight matrices by assigning the new values \n",
    "        from the active nodes\n",
    "        \"\"\"\n",
    " \n",
    "        temp = self.wei_inp_hid_orig.copy()[:,active_input_indices]\n",
    "        temp[active_hidden_indices] = self.wei_inp_hid\n",
    "        self.wei_inp_hid_orig[:, active_input_indices] = temp\n",
    "        self.wei_inp_hid = self.wei_inp_hid_orig.copy()\n",
    "        self.wei_hid_out_orig[:, active_hidden_indices] = self.wei_hid_out\n",
    "        self.wei_hid_out = self.wei_hid_out_orig.copy()\n",
    "        self.no_of_in_nodes = self.no_of_in_nodes_orig\n",
    "        self.no_of_hidden_nodes = self.no_of_hidden_nodes_orig\n",
    " \n",
    "           \n",
    "    \n",
    "    def train_single(self, input_vector, target_vector):\n",
    "        \"\"\" \n",
    "        input_vector and target_vector can be tuple, list or ndarray\n",
    "        \"\"\"\n",
    " \n",
    "        if self.bias:\n",
    "            # adding bias node to the end of the input_vector\n",
    "            input_vector = np.concatenate( (input_vector, [self.bias]) )\n",
    "        input_vector = np.array(input_vector, ndmin=2).T\n",
    "        target_vector = np.array(target_vector, ndmin=2).T\n",
    "        output_vector1 = np.dot(self.wei_inp_hid, input_vector)\n",
    "        output_vector_hidden = activation_function(output_vector1)\n",
    "        \n",
    "        if self.bias:\n",
    "            output_vector_hidden = np.concatenate( (output_vector_hidden, [[self.bias]]) )\n",
    "        \n",
    "        output_vector2 = np.dot(self.wei_hid_out, output_vector_hidden)\n",
    "        output_vector_network = activation_function(output_vector2)\n",
    "        \n",
    "        output_errors = target_vector - output_vector_network\n",
    "        # update the weights:\n",
    "        tmp = output_errors * output_vector_network * (1.0 - output_vector_network)     \n",
    "        tmp = self.learning_rate  * np.dot(tmp, output_vector_hidden.T)\n",
    "        self.wei_hid_out += tmp\n",
    "        # calculate hidden errors:\n",
    "        hidden_errors = np.dot(self.wei_hid_out.T, output_errors)\n",
    "        # update the weights:\n",
    "        tmp = hidden_errors * output_vector_hidden * (1.0 - output_vector_hidden)\n",
    "        if self.bias:\n",
    "            x = np.dot(tmp, input_vector.T)[:-1,:] \n",
    "        else:\n",
    "            x = np.dot(tmp, input_vector.T)\n",
    "        self.wei_inp_hid += self.learning_rate * x\n",
    "            \n",
    "        \n",
    "    def train(self, data_array, \n",
    "              labels_one_hot_array,\n",
    "              epochs=1,\n",
    "              active_input_percentage=0.70,\n",
    "              active_hidden_percentage=0.70,\n",
    "              no_of_dropout_tests = 10):\n",
    "        partition_length = int(len(data_array) / no_of_dropout_tests)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            print(\"epoch: \", epoch)\n",
    "            for start in range(0, len(data_array), partition_length):\n",
    "                active_in_indices, active_hidden_indices = \\\n",
    "                           self.dropout_weight_matrices(active_input_percentage,\n",
    "                                                        active_hidden_percentage)\n",
    "                for i in range(start, start + partition_length):\n",
    "                    self.train_single(data_array[i][active_in_indices], \n",
    "                                     labels_one_hot_array[i]) \n",
    "                    \n",
    "                self.weight_matrices_reset(active_in_indices, active_hidden_indices)\n",
    "      \n",
    "    \n",
    "    def confusion_matrix(self, data_array, labels):\n",
    "        cm = {}\n",
    "        for i in range(len(data_array)):\n",
    "            res = self.run(data_array[i])\n",
    "            res_max = res.argmax()\n",
    "            target = labels[i][0]\n",
    "            if (target, res_max) in cm:\n",
    "                cm[(target, res_max)] += 1\n",
    "            else:\n",
    "                cm[(target, res_max)] = 1\n",
    "        return cm\n",
    "        \n",
    "    \n",
    "    def run(self, input_vector):\n",
    "        # input_vector can be tuple, list or ndarray\n",
    "        \n",
    "        if self.bias:\n",
    "            # adding bias node to the end of the input_vector\n",
    "            input_vector = np.concatenate( (input_vector, [self.bias]) )\n",
    "        input_vector = np.array(input_vector, ndmin=2).T\n",
    "        output_vector = np.dot(self.wei_inp_hid, input_vector)\n",
    "        output_vector = activation_function(output_vector)\n",
    "        \n",
    "        if self.bias:\n",
    "            output_vector = np.concatenate( (output_vector, [[self.bias]]) )\n",
    "            \n",
    "        output_vector = np.dot(self.wei_hid_out, output_vector)\n",
    "        output_vector = activation_function(output_vector)\n",
    "    \n",
    "        return output_vector\n",
    "    \n",
    "    \n",
    "    def evaluate(self, data, labels):\n",
    "        corrects, wrongs = 0, 0\n",
    "        for i in range(len(data)):\n",
    "            res = self.run(data[i])\n",
    "            res_max = res.argmax()\n",
    "            if res_max == labels[i]:\n",
    "                corrects += 1\n",
    "            else:\n",
    "                wrongs += 1\n",
    "        return corrects, wrongs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7., 0., 0., ..., 0., 0., 0.],\n",
       "       [2., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [9., 0., 0., ..., 0., 0., 0.],\n",
       "       [5., 0., 0., ..., 0., 0., 0.],\n",
       "       [9., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "image_size = 28 # width and length\n",
    "no_of_different_labels = 10 #  i.e. 0, 1, 2, 3, ..., 9\n",
    "image_pixels = image_size * image_size\n",
    "train_data = np.loadtxt(\"mnist_train.csv\", \n",
    "                        delimiter=\",\")\n",
    "test_data = np.loadtxt(\"mnist_test.csv\", \n",
    "                       delimiter=\",\") \n",
    "test_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 785)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[test_data==255]\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "fac = 0.99 / 255\n",
    "train_imgs = np.asfarray(train_data[:, 1:]) * fac + 0.01\n",
    "test_imgs = np.asfarray(test_data[:, 1:]) * fac + 0.01\n",
    "train_labels = np.asfarray(train_data[:, :1])\n",
    "test_labels = np.asfarray(test_data[:, :1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  0  in one-hot representation:  [1 0 0 0 0 0 0 0 0 0]\n",
      "label:  1  in one-hot representation:  [0 1 0 0 0 0 0 0 0 0]\n",
      "label:  2  in one-hot representation:  [0 0 1 0 0 0 0 0 0 0]\n",
      "label:  3  in one-hot representation:  [0 0 0 1 0 0 0 0 0 0]\n",
      "label:  4  in one-hot representation:  [0 0 0 0 1 0 0 0 0 0]\n",
      "label:  5  in one-hot representation:  [0 0 0 0 0 1 0 0 0 0]\n",
      "label:  6  in one-hot representation:  [0 0 0 0 0 0 1 0 0 0]\n",
      "label:  7  in one-hot representation:  [0 0 0 0 0 0 0 1 0 0]\n",
      "label:  8  in one-hot representation:  [0 0 0 0 0 0 0 0 1 0]\n",
      "label:  9  in one-hot representation:  [0 0 0 0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "lr = np.arange(10)\n",
    "for label in range(10):\n",
    "    one_hot = (lr==label).astype(np.int)\n",
    "    print(\"label: \", label, \" in one-hot representation: \", one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = np.arange(no_of_different_labels)\n",
    "# transform labels into one hot representation\n",
    "train_labels_one_hot = (lr==train_labels).astype(np.float)\n",
    "test_labels_one_hot = (lr==test_labels).astype(np.float)\n",
    "# we don't want zeroes and ones in the labels neither:\n",
    "train_labels_one_hot[train_labels_one_hot==0] = 0.01\n",
    "train_labels_one_hot[train_labels_one_hot==1] = 0.99\n",
    "test_labels_one_hot[test_labels_one_hot==0] = 0.01\n",
    "test_labels_one_hot[test_labels_one_hot==1] = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 28 # width and length\n",
    "no_of_different_labels = 10 #  i.e. 0, 1, 2, 3, ..., 9\n",
    "image_pixels = image_size * image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n",
      "0 6000\n",
      "6000 12000\n",
      "12000 18000\n",
      "18000 24000\n",
      "24000 30000\n",
      "30000 36000\n",
      "36000 42000\n",
      "42000 48000\n",
      "48000 54000\n",
      "54000 60000\n"
     ]
    }
   ],
   "source": [
    "parts = 10\n",
    "partition_length = int(len(train_imgs) / parts)\n",
    "print(partition_length)\n",
    "start = 0\n",
    "for start in range(0, len(train_imgs), partition_length):\n",
    "    print(start, start + partition_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "epoch:  1\n",
      "epoch:  2\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "simple_network = NeuralNetwork(no_of_in_nodes = image_pixels, \n",
    "                               no_of_out_nodes = 10, \n",
    "                               no_of_hidden_nodes = 100,\n",
    "                               learning_rate = 0.1)\n",
    "    \n",
    "    \n",
    " \n",
    "simple_network.train(train_imgs, \n",
    "                     train_labels_one_hot, \n",
    "                     active_input_percentage=1,\n",
    "                     active_hidden_percentage=1,\n",
    "                     no_of_dropout_tests = 100,\n",
    "                     epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accruracy train:  0.9022666666666667\n",
      "accruracy: test 0.8982\n"
     ]
    }
   ],
   "source": [
    "corrects, wrongs = simple_network.evaluate(train_imgs, train_labels)\n",
    "print(\"accruracy train: \", corrects / ( corrects + wrongs))\n",
    "corrects, wrongs = simple_network.evaluate(test_imgs, test_labels)\n",
    "print(\"accruracy: test\", corrects / ( corrects + wrongs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
